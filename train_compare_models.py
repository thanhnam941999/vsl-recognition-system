#!/usr/bin/env python3
"""
Train v√† so s√°nh 3 m√¥ h√¨nh:
1. Random Forest
2. LSTM
3. CNN-LSTM
"""

import numpy as np
import pandas as pd
import json
import time
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# Thi·∫øt l·∫≠p
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['figure.dpi'] = 100

class DataLoader:
    """Load v√† x·ª≠ l√Ω d·ªØ li·ªáu"""

    def __init__(self, data_dir='data'):
        self.data_dir = Path(data_dir)
        self.metadata = pd.read_csv(self.data_dir / 'metadata.csv')

        with open(self.data_dir / 'sign_mapping.json', 'r', encoding='utf-8') as f:
            self.sign_mapping = json.load(f)

        self.num_signs = len(self.sign_mapping)

    def load_all_data(self):
        """Load to√†n b·ªô d·ªØ li·ªáu"""
        X = []
        y = []

        print("ƒêang load d·ªØ li·ªáu...")
        for _, row in tqdm(self.metadata.iterrows(), total=len(self.metadata)):
            # Load landmarks
            landmarks = np.load(row['filepath'])
            X.append(landmarks)
            y.append(row['sign_id'])

        X = np.array(X)
        y = np.array(y)

        print(f"‚úÖ ƒê√£ load {len(X)} m·∫´u")
        print(f"   Shape: {X.shape}")

        return X, y

    def split_data(self, X, y, test_size=0.2, val_size=0.1):
        """Chia train/val/test"""
        # Chia theo ng∆∞·ªùi ƒë·ªÉ tr√°nh data leakage
        people = self.metadata['person_id'].unique()

        # 80% train, 10% val, 10% test
        n_train = int(len(people) * (1 - test_size - val_size))
        n_val = int(len(people) * val_size)

        np.random.shuffle(people)
        train_people = people[:n_train]
        val_people = people[n_train:n_train+n_val]
        test_people = people[n_train+n_val:]

        # L·∫•y indices
        train_idx = self.metadata[self.metadata['person_id'].isin(train_people)].index
        val_idx = self.metadata[self.metadata['person_id'].isin(val_people)].index
        test_idx = self.metadata[self.metadata['person_id'].isin(test_people)].index

        X_train, y_train = X[train_idx], y[train_idx]
        X_val, y_val = X[val_idx], y[val_idx]
        X_test, y_test = X[test_idx], y[test_idx]

        print(f"\nüìä Ph√¢n chia d·ªØ li·ªáu:")
        print(f"   Train: {len(X_train)} m·∫´u ({len(train_people)} ng∆∞·ªùi)")
        print(f"   Val:   {len(X_val)} m·∫´u ({len(val_people)} ng∆∞·ªùi)")
        print(f"   Test:  {len(X_test)} m·∫´u ({len(test_people)} ng∆∞·ªùi)")

        return (X_train, y_train), (X_val, y_val), (X_test, y_test)


class RandomForestModel:
    """M√¥ h√¨nh Random Forest"""

    def __init__(self, n_estimators=100, max_depth=20):
        self.model = RandomForestClassifier(
            n_estimators=n_estimators,
            max_depth=max_depth,
            random_state=42,
            n_jobs=-1
        )
        self.name = "Random Forest"

    def prepare_data(self, X):
        """Flatten d·ªØ li·ªáu 3D th√†nh 2D"""
        return X.reshape(X.shape[0], -1)

    def train(self, X_train, y_train, X_val=None, y_val=None):
        """Train m√¥ h√¨nh"""
        print(f"\n{'='*60}")
        print(f"TRAINING {self.name}")
        print(f"{'='*60}")

        # Flatten data
        X_train_flat = self.prepare_data(X_train)

        # Train
        start_time = time.time()
        self.model.fit(X_train_flat, y_train)
        train_time = time.time() - start_time

        # Evaluate
        y_pred = self.model.predict(X_train_flat)
        train_acc = accuracy_score(y_train, y_pred)

        print(f"‚úÖ Ho√†n th√†nh training")
        print(f"   Th·ªùi gian: {train_time:.2f}s")
        print(f"   Train accuracy: {train_acc:.4f}")

        return {
            'train_time': train_time,
            'train_accuracy': train_acc
        }

    def evaluate(self, X_test, y_test):
        """ƒê√°nh gi√° m√¥ h√¨nh"""
        X_test_flat = self.prepare_data(X_test)

        start_time = time.time()
        y_pred = self.model.predict(X_test_flat)
        inference_time = (time.time() - start_time) / len(X_test) * 1000  # ms

        accuracy = accuracy_score(y_test, y_pred)

        print(f"\nüìä K·∫øt qu·∫£ test:")
        print(f"   Accuracy: {accuracy:.4f}")
        print(f"   Inference time: {inference_time:.2f}ms/sample")

        return {
            'accuracy': accuracy,
            'inference_time': inference_time,
            'y_pred': y_pred
        }


class LSTMModel:
    """M√¥ h√¨nh LSTM thu·∫ßn"""

    def __init__(self, input_shape, num_classes):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.name = "LSTM"
        self.build_model()

    def build_model(self):
        """X√¢y d·ª±ng ki·∫øn tr√∫c"""
        model = keras.Sequential([
            layers.Input(shape=self.input_shape),

            # Flatten landmarks th√†nh vector cho m·ªói frame
            layers.Reshape((self.input_shape[0], -1)),

            # LSTM layers
            layers.LSTM(128, return_sequences=True),
            layers.Dropout(0.3),

            layers.LSTM(128),
            layers.Dropout(0.3),

            # Output
            layers.Dense(self.num_classes, activation='softmax')
        ])

        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        self.model = model
        print(f"\nüèóÔ∏è  Ki·∫øn tr√∫c {self.name}:")
        self.model.summary()

    def train(self, X_train, y_train, X_val, y_val, epochs=50):
        """Train m√¥ h√¨nh"""
        print(f"\n{'='*60}")
        print(f"TRAINING {self.name}")
        print(f"{'='*60}")

        start_time = time.time()

        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=32,
            callbacks=[
                keras.callbacks.EarlyStopping(
                    patience=10,
                    restore_best_weights=True
                ),
                keras.callbacks.ReduceLROnPlateau(
                    factor=0.5,
                    patience=5
                )
            ],
            verbose=1
        )

        train_time = time.time() - start_time

        print(f"‚úÖ Ho√†n th√†nh training")
        print(f"   Th·ªùi gian: {train_time:.2f}s")

        return {
            'train_time': train_time,
            'history': history.history
        }

    def evaluate(self, X_test, y_test):
        """ƒê√°nh gi√° m√¥ h√¨nh"""
        start_time = time.time()
        y_pred_proba = self.model.predict(X_test, verbose=0)
        inference_time = (time.time() - start_time) / len(X_test) * 1000

        y_pred = np.argmax(y_pred_proba, axis=1)
        accuracy = accuracy_score(y_test, y_pred)

        print(f"\nüìä K·∫øt qu·∫£ test:")
        print(f"   Accuracy: {accuracy:.4f}")
        print(f"   Inference time: {inference_time:.2f}ms/sample")

        return {
            'accuracy': accuracy,
            'inference_time': inference_time,
            'y_pred': y_pred
        }


class CNNLSTMModel:
    """M√¥ h√¨nh CNN-LSTM k·∫øt h·ª£p"""

    def __init__(self, input_shape, num_classes):
        self.input_shape = input_shape
        self.num_classes = num_classes
        self.name = "CNN-LSTM"
        self.build_model()

    def build_model(self):
        """X√¢y d·ª±ng ki·∫øn tr√∫c"""
        model = keras.Sequential([
            layers.Input(shape=self.input_shape),

            # Reshape ƒë·ªÉ d√πng Conv1D
            layers.Reshape((self.input_shape[0], -1)),

            # CNN layers - tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng kh√¥ng gian
            layers.Conv1D(32, kernel_size=3, activation='relu', padding='same'),
            layers.MaxPooling1D(pool_size=2),

            layers.Conv1D(64, kernel_size=3, activation='relu', padding='same'),
            layers.MaxPooling1D(pool_size=2),

            # LSTM layers - h·ªçc quan h·ªá th·ªùi gian
            layers.LSTM(128, return_sequences=True),
            layers.Dropout(0.3),

            layers.LSTM(128),
            layers.Dropout(0.3),

            # Output
            layers.Dense(self.num_classes, activation='softmax')
        ])

        model.compile(
            optimizer='adam',
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy']
        )

        self.model = model
        print(f"\nüèóÔ∏è  Ki·∫øn tr√∫c {self.name}:")
        self.model.summary()

    def train(self, X_train, y_train, X_val, y_val, epochs=50):
        """Train m√¥ h√¨nh"""
        print(f"\n{'='*60}")
        print(f"TRAINING {self.name}")
        print(f"{'='*60}")

        start_time = time.time()

        history = self.model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=epochs,
            batch_size=32,
            callbacks=[
                keras.callbacks.EarlyStopping(
                    patience=10,
                    restore_best_weights=True
                ),
                keras.callbacks.ReduceLROnPlateau(
                    factor=0.5,
                    patience=5
                )
            ],
            verbose=1
        )

        train_time = time.time() - start_time

        print(f"‚úÖ Ho√†n th√†nh training")
        print(f"   Th·ªùi gian: {train_time:.2f}s")

        return {
            'train_time': train_time,
            'history': history.history
        }

    def evaluate(self, X_test, y_test):
        """ƒê√°nh gi√° m√¥ h√¨nh"""
        start_time = time.time()
        y_pred_proba = self.model.predict(X_test, verbose=0)
        inference_time = (time.time() - start_time) / len(X_test) * 1000

        y_pred = np.argmax(y_pred_proba, axis=1)
        accuracy = accuracy_score(y_test, y_pred)

        print(f"\nüìä K·∫øt qu·∫£ test:")
        print(f"   Accuracy: {accuracy:.4f}")
        print(f"   Inference time: {inference_time:.2f}ms/sample")

        return {
            'accuracy': accuracy,
            'inference_time': inference_time,
            'y_pred': y_pred
        }


def plot_comparison(results, output_dir='outputs'):
    """V·∫Ω bi·ªÉu ƒë·ªì so s√°nh"""
    output_dir = Path(output_dir)
    output_dir.mkdir(exist_ok=True)

    models = list(results.keys())

    # 1. So s√°nh accuracy
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))

    # Accuracy
    accuracies = [results[m]['test_accuracy'] * 100 for m in models]
    colors = ['#90CAF9', '#FFB74D', '#81C784']

    axes[0, 0].bar(models, accuracies, color=colors, alpha=0.8, edgecolor='black')
    axes[0, 0].set_ylabel('Accuracy (%)')
    axes[0, 0].set_title('ƒê·ªô ch√≠nh x√°c', fontweight='bold')
    axes[0, 0].set_ylim(0, 100)
    axes[0, 0].grid(True, alpha=0.3, axis='y')
    for i, v in enumerate(accuracies):
        axes[0, 0].text(i, v + 2, f'{v:.1f}%', ha='center', fontweight='bold')

    # Training time
    train_times = [results[m]['train_time'] / 60 for m in models]  # ph√∫t
    axes[0, 1].bar(models, train_times, color=colors, alpha=0.8, edgecolor='black')
    axes[0, 1].set_ylabel('Th·ªùi gian (ph√∫t)')
    axes[0, 1].set_title('Th·ªùi gian hu·∫•n luy·ªán', fontweight='bold')
    axes[0, 1].grid(True, alpha=0.3, axis='y')
    for i, v in enumerate(train_times):
        axes[0, 1].text(i, v + 0.1, f'{v:.1f}m', ha='center', fontweight='bold')

    # Inference time
    inference_times = [results[m]['inference_time'] for m in models]
    axes[1, 0].bar(models, inference_times, color=colors, alpha=0.8, edgecolor='black')
    axes[1, 0].set_ylabel('Th·ªùi gian (ms)')
    axes[1, 0].set_title('Th·ªùi gian suy lu·∫≠n', fontweight='bold')
    axes[1, 0].grid(True, alpha=0.3, axis='y')
    for i, v in enumerate(inference_times):
        axes[1, 0].text(i, v + 2, f'{v:.0f}ms', ha='center', fontweight='bold')

    # Model size (gi·∫£ ƒë·ªãnh)
    model_sizes = [15, 25, 50]  # MB
    axes[1, 1].bar(models, model_sizes, color=colors, alpha=0.8, edgecolor='black')
    axes[1, 1].set_ylabel('K√≠ch th∆∞·ªõc (MB)')
    axes[1, 1].set_title('K√≠ch th∆∞·ªõc m√¥ h√¨nh (∆∞·ªõc t√≠nh)', fontweight='bold')
    axes[1, 1].grid(True, alpha=0.3, axis='y')
    for i, v in enumerate(model_sizes):
        axes[1, 1].text(i, v + 1.5, f'{v}MB', ha='center', fontweight='bold')

    plt.suptitle('SO S√ÅNH HI·ªÜU SU·∫§T BA PH∆Ø∆†NG PH√ÅP', fontsize=15, fontweight='bold')
    plt.tight_layout()
    plt.savefig(output_dir / 'comparison.png', dpi=150, bbox_inches='tight')
    print(f"\n‚úÖ ƒê√£ l∆∞u: {output_dir / 'comparison.png'}")

    # 2. B·∫£ng so s√°nh
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.axis('tight')
    ax.axis('off')

    table_data = []
    table_data.append(['Ph∆∞∆°ng ph√°p', 'Accuracy', 'Th·ªùi gian train', 'Th·ªùi gian suy lu·∫≠n', 'K√≠ch th∆∞·ªõc'])
    for i, model in enumerate(models):
        table_data.append([
            model,
            f"{results[model]['test_accuracy']*100:.1f}%",
            f"{results[model]['train_time']/60:.1f} ph√∫t",
            f"{results[model]['inference_time']:.0f} ms",
            f"{model_sizes[i]} MB"
        ])

    table = ax.table(cellText=table_data, cellLoc='center', loc='center',
                     colWidths=[0.25, 0.15, 0.2, 0.2, 0.2])
    table.auto_set_font_size(False)
    table.set_fontsize(10)
    table.scale(1, 2)

    # Style header
    for i in range(5):
        table[(0, i)].set_facecolor('#4CAF50')
        table[(0, i)].set_text_props(weight='bold', color='white')

    # Style data rows
    for i in range(1, 4):
        for j in range(5):
            table[(i, j)].set_facecolor(['#E3F2FD', '#FFF3E0', '#E8F5E9'][i-1])

    plt.title('B·∫¢NG SO S√ÅNH CHI TI·∫æT', fontsize=14, fontweight='bold', pad=20)
    plt.savefig(output_dir / 'comparison_table.png', dpi=150, bbox_inches='tight')
    print(f"‚úÖ ƒê√£ l∆∞u: {output_dir / 'comparison_table.png'}")


def main():
    """H√†m ch√≠nh"""
    print("\n" + "="*60)
    print("TRAIN V√Ä SO S√ÅNH 3 M√î H√åNH NH·∫¨N D·∫†NG VSL")
    print("="*60)

    # Load d·ªØ li·ªáu
    loader = DataLoader()
    X, y = loader.load_all_data()

    # Chia d·ªØ li·ªáu
    (X_train, y_train), (X_val, y_val), (X_test, y_test) = loader.split_data(X, y)

    input_shape = X_train.shape[1:]  # (num_frames, num_landmarks, num_coords)
    num_classes = loader.num_signs

    # K·∫øt qu·∫£
    results = {}

    # 1. Random Forest
    print("\n" + "üå≥ "*20)
    rf_model = RandomForestModel()
    rf_train_results = rf_model.train(X_train, y_train, X_val, y_val)
    rf_test_results = rf_model.evaluate(X_test, y_test)

    results['Random Forest'] = {
        'train_time': rf_train_results['train_time'],
        'test_accuracy': rf_test_results['accuracy'],
        'inference_time': rf_test_results['inference_time']
    }

    # 2. LSTM
    print("\n" + "üîÑ "*20)
    lstm_model = LSTMModel(input_shape, num_classes)
    lstm_train_results = lstm_model.train(X_train, y_train, X_val, y_val, epochs=30)
    lstm_test_results = lstm_model.evaluate(X_test, y_test)

    results['LSTM'] = {
        'train_time': lstm_train_results['train_time'],
        'test_accuracy': lstm_test_results['accuracy'],
        'inference_time': lstm_test_results['inference_time']
    }

    # 3. CNN-LSTM
    print("\n" + "üî• "*20)
    cnn_lstm_model = CNNLSTMModel(input_shape, num_classes)
    cnn_lstm_train_results = cnn_lstm_model.train(X_train, y_train, X_val, y_val, epochs=30)
    cnn_lstm_test_results = cnn_lstm_model.evaluate(X_test, y_test)

    results['CNN-LSTM'] = {
        'train_time': cnn_lstm_train_results['train_time'],
        'test_accuracy': cnn_lstm_test_results['accuracy'],
        'inference_time': cnn_lstm_test_results['inference_time']
    }

    # T·ªïng k·∫øt
    print("\n" + "="*60)
    print("T·ªîNG K·∫æT K·∫æT QU·∫¢")
    print("="*60)

    for model_name, res in results.items():
        print(f"\n{model_name}:")
        print(f"  ‚úì Accuracy: {res['test_accuracy']*100:.2f}%")
        print(f"  ‚úì Train time: {res['train_time']/60:.2f} ph√∫t")
        print(f"  ‚úì Inference time: {res['inference_time']:.2f} ms")

    # V·∫Ω bi·ªÉu ƒë·ªì
    plot_comparison(results)

    # L∆∞u k·∫øt qu·∫£
    output_dir = Path('outputs')
    output_dir.mkdir(exist_ok=True)

    with open(output_dir / 'results.json', 'w') as f:
        json.dump(results, f, indent=2)

    print(f"\n‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£: {output_dir / 'results.json'}")
    print("\n" + "="*60)
    print("HO√ÄN TH√ÄNH!")
    print("="*60 + "\n")


if __name__ == "__main__":
    main()